{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use\n",
    "The datasets library allows you to load and pre-process your dataset in pure Python, at scale. The dataset can be downloaded and prepared in one call to your local drive by using the load_dataset function.\n",
    "\n",
    "For example, to download the persian config, simply specify the corresponding language config name (i.e., \"fa_ir\" for persian):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mehdi\\Documents\\GitHub\\hugging\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading builder script: 100%|██████████| 12.6k/12.6k [00:00<00:00, 12.6MB/s]\n",
      "Downloading readme: 100%|██████████| 13.3k/13.3k [00:00<00:00, 13.4MB/s]\n",
      "Downloading data: 100%|██████████| 2.14G/2.14G [23:07<00:00, 1.54MB/s]\n",
      "Downloading data: 100%|██████████| 272M/272M [02:51<00:00, 1.58MB/s]it]\n",
      "Downloading data: 100%|██████████| 657M/657M [07:57<00:00, 1.38MB/s]t] \n",
      "Downloading data files: 100%|██████████| 3/3 [34:06<00:00, 682.12s/it]\n",
      "Extracting data files: 100%|██████████| 3/3 [00:31<00:00, 10.38s/it]\n",
      "Downloading data: 100%|██████████| 2.48M/2.48M [00:02<00:00, 1.22MB/s]\n",
      "Downloading data: 100%|██████████| 290k/290k [00:00<00:00, 804kB/s]t]\n",
      "Downloading data: 100%|██████████| 708k/708k [00:00<00:00, 891kB/s] ]\n",
      "Downloading data files: 100%|██████████| 3/3 [00:06<00:00,  2.06s/it]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n"
     ]
    },
    {
     "ename": "DatasetGenerationError",
     "evalue": "An error occurred while generating the dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Mehdi\\Documents\\GitHub\\hugging\\.venv\\Lib\\site-packages\\datasets\\features\\audio.py:91\u001b[0m, in \u001b[0;36mAudio.encode_example\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 91\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39msoundfile\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msf\u001b[39;00m  \u001b[39m# soundfile is a dependency of librosa, needed to decode audio files.\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'soundfile'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Mehdi\\Documents\\GitHub\\hugging\\.venv\\Lib\\site-packages\\datasets\\builder.py:1693\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[0m\n\u001b[0;32m   1684\u001b[0m     writer \u001b[39m=\u001b[39m writer_class(\n\u001b[0;32m   1685\u001b[0m         features\u001b[39m=\u001b[39mwriter\u001b[39m.\u001b[39m_features,\n\u001b[0;32m   1686\u001b[0m         path\u001b[39m=\u001b[39mfpath\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mSSSSS\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mshard_id\u001b[39m:\u001b[39;00m\u001b[39m05d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mJJJJJ\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mjob_id\u001b[39m:\u001b[39;00m\u001b[39m05d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1691\u001b[0m         embed_local_files\u001b[39m=\u001b[39membed_local_files,\n\u001b[0;32m   1692\u001b[0m     )\n\u001b[1;32m-> 1693\u001b[0m example \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfo\u001b[39m.\u001b[39;49mfeatures\u001b[39m.\u001b[39;49mencode_example(record) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mfeatures \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m record\n\u001b[0;32m   1694\u001b[0m writer\u001b[39m.\u001b[39mwrite(example, key)\n",
      "File \u001b[1;32mc:\\Users\\Mehdi\\Documents\\GitHub\\hugging\\.venv\\Lib\\site-packages\\datasets\\features\\features.py:1851\u001b[0m, in \u001b[0;36mFeatures.encode_example\u001b[1;34m(self, example)\u001b[0m\n\u001b[0;32m   1850\u001b[0m example \u001b[39m=\u001b[39m cast_to_python_objects(example)\n\u001b[1;32m-> 1851\u001b[0m \u001b[39mreturn\u001b[39;00m encode_nested_example(\u001b[39mself\u001b[39;49m, example)\n",
      "File \u001b[1;32mc:\\Users\\Mehdi\\Documents\\GitHub\\hugging\\.venv\\Lib\\site-packages\\datasets\\features\\features.py:1229\u001b[0m, in \u001b[0;36mencode_nested_example\u001b[1;34m(schema, obj, level)\u001b[0m\n\u001b[0;32m   1227\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mGot None but expected a dictionary instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1228\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m-> 1229\u001b[0m         {\n\u001b[0;32m   1230\u001b[0m             k: encode_nested_example(sub_schema, sub_obj, level\u001b[39m=\u001b[39;49mlevel \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[0;32m   1231\u001b[0m             \u001b[39mfor\u001b[39;49;00m k, (sub_schema, sub_obj) \u001b[39min\u001b[39;49;00m zip_dict(schema, obj)\n\u001b[0;32m   1232\u001b[0m         }\n\u001b[0;32m   1233\u001b[0m         \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1234\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1235\u001b[0m     )\n\u001b[0;32m   1237\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(schema, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n",
      "File \u001b[1;32mc:\\Users\\Mehdi\\Documents\\GitHub\\hugging\\.venv\\Lib\\site-packages\\datasets\\features\\features.py:1230\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1227\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mGot None but expected a dictionary instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1228\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m   1229\u001b[0m         {\n\u001b[1;32m-> 1230\u001b[0m             k: encode_nested_example(sub_schema, sub_obj, level\u001b[39m=\u001b[39;49mlevel \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[0;32m   1231\u001b[0m             \u001b[39mfor\u001b[39;00m k, (sub_schema, sub_obj) \u001b[39min\u001b[39;00m zip_dict(schema, obj)\n\u001b[0;32m   1232\u001b[0m         }\n\u001b[0;32m   1233\u001b[0m         \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1234\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1235\u001b[0m     )\n\u001b[0;32m   1237\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(schema, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n",
      "File \u001b[1;32mc:\\Users\\Mehdi\\Documents\\GitHub\\hugging\\.venv\\Lib\\site-packages\\datasets\\features\\features.py:1284\u001b[0m, in \u001b[0;36mencode_nested_example\u001b[1;34m(schema, obj, level)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(schema, (Audio, Image, ClassLabel, TranslationVariableLanguages, Value, _ArrayXD)):\n\u001b[1;32m-> 1284\u001b[0m     \u001b[39mreturn\u001b[39;00m schema\u001b[39m.\u001b[39;49mencode_example(obj) \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[39m# Other object should be directly convertible to a native Arrow type (like Translation and Translation)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mehdi\\Documents\\GitHub\\hugging\\.venv\\Lib\\site-packages\\datasets\\features\\audio.py:93\u001b[0m, in \u001b[0;36mAudio.encode_example\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTo support encoding audio data, please install \u001b[39m\u001b[39m'\u001b[39m\u001b[39msoundfile\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mstr\u001b[39m):\n",
      "\u001b[1;31mImportError\u001b[0m: To support encoding audio data, please install 'soundfile'.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatasetGenerationError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[1;32m----> 2\u001b[0m fleurs \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mgoogle/fleurs\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfa_ir\u001b[39;49m\u001b[39m\"\u001b[39;49m, split\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Mehdi\\Documents\\GitHub\\hugging\\.venv\\Lib\\site-packages\\datasets\\load.py:2133\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   2130\u001b[0m try_from_hf_gcs \u001b[39m=\u001b[39m path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[0;32m   2132\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n\u001b[1;32m-> 2133\u001b[0m builder_instance\u001b[39m.\u001b[39;49mdownload_and_prepare(\n\u001b[0;32m   2134\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m   2135\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[0;32m   2136\u001b[0m     verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[0;32m   2137\u001b[0m     try_from_hf_gcs\u001b[39m=\u001b[39;49mtry_from_hf_gcs,\n\u001b[0;32m   2138\u001b[0m     num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[0;32m   2139\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   2140\u001b[0m )\n\u001b[0;32m   2142\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[0;32m   2143\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[0;32m   2144\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[0;32m   2145\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Mehdi\\Documents\\GitHub\\hugging\\.venv\\Lib\\site-packages\\datasets\\builder.py:954\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    952\u001b[0m     \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m         prepare_split_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_proc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_proc\n\u001b[1;32m--> 954\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[0;32m    955\u001b[0m         dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[0;32m    956\u001b[0m         verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[0;32m    957\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs,\n\u001b[0;32m    958\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdownload_and_prepare_kwargs,\n\u001b[0;32m    959\u001b[0m     )\n\u001b[0;32m    960\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n\u001b[0;32m    961\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n",
      "File \u001b[1;32mc:\\Users\\Mehdi\\Documents\\GitHub\\hugging\\.venv\\Lib\\site-packages\\datasets\\builder.py:1717\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_download_and_prepare\u001b[39m(\u001b[39mself\u001b[39m, dl_manager, verification_mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_splits_kwargs):\n\u001b[1;32m-> 1717\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[0;32m   1718\u001b[0m         dl_manager,\n\u001b[0;32m   1719\u001b[0m         verification_mode,\n\u001b[0;32m   1720\u001b[0m         check_duplicate_keys\u001b[39m=\u001b[39;49mverification_mode \u001b[39m==\u001b[39;49m VerificationMode\u001b[39m.\u001b[39;49mBASIC_CHECKS\n\u001b[0;32m   1721\u001b[0m         \u001b[39mor\u001b[39;49;00m verification_mode \u001b[39m==\u001b[39;49m VerificationMode\u001b[39m.\u001b[39;49mALL_CHECKS,\n\u001b[0;32m   1722\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_splits_kwargs,\n\u001b[0;32m   1723\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Mehdi\\Documents\\GitHub\\hugging\\.venv\\Lib\\site-packages\\datasets\\builder.py:1049\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m   1045\u001b[0m split_dict\u001b[39m.\u001b[39madd(split_generator\u001b[39m.\u001b[39msplit_info)\n\u001b[0;32m   1047\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1048\u001b[0m     \u001b[39m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[1;32m-> 1049\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_split(split_generator, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs)\n\u001b[0;32m   1050\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1051\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[0;32m   1052\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot find data file. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1053\u001b[0m         \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_download_instructions \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1054\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal error:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1055\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)\n\u001b[0;32m   1056\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mehdi\\Documents\\GitHub\\hugging\\.venv\\Lib\\site-packages\\datasets\\builder.py:1555\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split\u001b[1;34m(self, split_generator, check_duplicate_keys, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[0;32m   1553\u001b[0m job_id \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m   1554\u001b[0m \u001b[39mwith\u001b[39;00m pbar:\n\u001b[1;32m-> 1555\u001b[0m     \u001b[39mfor\u001b[39;00m job_id, done, content \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_split_single(\n\u001b[0;32m   1556\u001b[0m         gen_kwargs\u001b[39m=\u001b[39mgen_kwargs, job_id\u001b[39m=\u001b[39mjob_id, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_prepare_split_args\n\u001b[0;32m   1557\u001b[0m     ):\n\u001b[0;32m   1558\u001b[0m         \u001b[39mif\u001b[39;00m done:\n\u001b[0;32m   1559\u001b[0m             result \u001b[39m=\u001b[39m content\n",
      "File \u001b[1;32mc:\\Users\\Mehdi\\Documents\\GitHub\\hugging\\.venv\\Lib\\site-packages\\datasets\\builder.py:1712\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[0m\n\u001b[0;32m   1710\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, SchemaInferenceError) \u001b[39mand\u001b[39;00m e\u001b[39m.\u001b[39m__context__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1711\u001b[0m         e \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39m__context__\n\u001b[1;32m-> 1712\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetGenerationError(\u001b[39m\"\u001b[39m\u001b[39mAn error occurred while generating the dataset\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1714\u001b[0m \u001b[39myield\u001b[39;00m job_id, \u001b[39mTrue\u001b[39;00m, (total_num_examples, total_num_bytes, writer\u001b[39m.\u001b[39m_features, num_shards, shard_lengths)\n",
      "\u001b[1;31mDatasetGenerationError\u001b[0m: An error occurred while generating the dataset"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "fleurs = load_dataset(\"google/fleurs\", \"fa_ir\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the datasets library, you can also stream the dataset on-the-fly by adding a streaming=True argument to the load_dataset function call. Loading a dataset in streaming mode loads individual samples of the dataset at a time, rather than downloading the entire dataset to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "fleurs = load_dataset(\"google/fleurs\", \"fa_ir\", split=\"train\", streaming=True)\n",
    "print(next(iter(fleurs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data.sampler import BatchSampler, RandomSampler\n",
    "fleurs = load_dataset(\"google/fleurs\", \"fa_ir\", split=\"train\")\n",
    "batch_sampler = BatchSampler(RandomSampler(fleurs), batch_size=32, drop_last=False)\n",
    "dataloader = DataLoader(fleurs, batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "fleurs = load_dataset(\"google/fleurs\", \"fa_ir\", split=\"train\")\n",
    "dataloader = DataLoader(fleurs, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Speech Recognition (ASR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "fleurs_asr = load_dataset(\"google/fleurs\", \"fa_ir\")  # for Afrikaans\n",
    "# to download all data for multi-lingual fine-tuning uncomment following line\n",
    "# fleurs_asr = load_dataset(\"google/fleurs\", \"all\")\n",
    "\n",
    "# see structure\n",
    "print(fleurs_asr)\n",
    "\n",
    "# load audio sample on the fly\n",
    "audio_input = fleurs_asr[\"train\"][0][\"audio\"]  # first decoded audio sample\n",
    "transcription = fleurs_asr[\"train\"][0][\"transcription\"]  # first transcription\n",
    "# use `audio_input` and `transcription` to fine-tune your model for ASR\n",
    "\n",
    "# for analyses see language groups\n",
    "all_language_groups = fleurs_asr[\"train\"].features[\"lang_group_id\"].names\n",
    "lang_group_id = fleurs_asr[\"train\"][0][\"lang_group_id\"]\n",
    "\n",
    "all_language_groups[lang_group_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Language Identification\n",
    "LangID can often be a domain classification, but in the case of FLEURS-LangID, recordings are done in a similar setting across languages and the utterances correspond to n-way parallel sentences, in the exact same domain, making this task particularly relevant for evaluating LangID. The setting is simple, FLEURS-LangID is splitted in train/valid/test for each language. We simply create a single train/valid/test for LangID by merging all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "fleurs_langID = load_dataset(\"google/fleurs\", \"all\") # to download all data\n",
    "\n",
    "# see structure\n",
    "print(fleurs_langID)\n",
    "\n",
    "# load audio sample on the fly\n",
    "audio_input = fleurs_langID[\"train\"][0][\"audio\"]  # first decoded audio sample\n",
    "language_class = fleurs_langID[\"train\"][0][\"lang_id\"]  # first id class\n",
    "language = fleurs_langID[\"train\"].features[\"lang_id\"].names[language_class]\n",
    "\n",
    "# use audio_input and language_class to fine-tune your model for audio classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retrieval\n",
    "Retrieval provides n-way parallel speech and text data. Similar to how XTREME for text leverages Tatoeba to evaluate bitext mining a.k.a sentence translation retrieval, we use Retrieval to evaluate the quality of fixed-size representations of speech utterances. Our goal is to incentivize the creation of fixed-size speech encoder for speech retrieval. The system has to retrieve the English \"key\" utterance corresponding to the speech translation of \"queries\" in 15 languages. Results have to be reported on the test sets of Retrieval whose utterances are used as queries (and keys for English). We augment the English keys with a large number of utterances to make the task more difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "fleurs_retrieval = load_dataset(\"google/fleurs\", \"fa_ir\")  # for Afrikaans\n",
    "# to download all data for multi-lingual fine-tuning uncomment following line\n",
    "# fleurs_retrieval = load_dataset(\"google/fleurs\", \"all\")\n",
    "\n",
    "# see structure\n",
    "print(fleurs_retrieval)\n",
    "\n",
    "# load audio sample on the fly\n",
    "audio_input = fleurs_retrieval[\"train\"][0][\"audio\"]  # decoded audio sample\n",
    "text_sample_pos = fleurs_retrieval[\"train\"][0][\"transcription\"]  # positive text sample\n",
    "text_sample_neg = fleurs_retrieval[\"train\"][1:20][\"transcription\"] # negative text samples\n",
    "\n",
    "# use `audio_input`, `text_sample_pos`, and `text_sample_neg` to fine-tune your model for retrieval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
